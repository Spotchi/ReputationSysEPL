In this part we will build a rating system for $N$ judges evaluating $M$ objects, each having a set of $K$ different characteristics. 
The judges give the objects some set of ratings $x_{ijk}$.
At the end of the iterative process, each rating $i$ will be given a weight $w_{ijk}$ and each object $j$ will be given a reputation $r_{jk}$.


\subsection*{Description of general filtering methods}
As defined in other works, an iterative filtering(IF) system is composed of two basic functions \cite{Cristo1} : 
\begin{itemize}
\item The reputation function : $F(w,X)=r$
\item The filtering function : $G(r,X)=w$
\end{itemize}
The two of them define an iterative filtering system.\\
In quadratic IF systems, the reputation function is naturally given by the weighted average of the votes.
$$F_{jk}(w,X) = \frac{\sum_{i}x_{ijk}w_{ijk}}{\sum_i w_{ijk}}$$

The filtering method used in the aforementioned paper adapted to a multi-variate system is $G_{ik}(w,X) = \log \prod_j f(x_{ijk}|r,C)$

\subsection*{Filtering algorithm specification}
Let us remember the guidelines we had for the choice of our filtering algorithm. It should be able to handle several cases :
\begin{itemize}
\item A judge rating one object much better than the others in a caracteristic should be given less influence
\item A judge rating with a mean rating above or below the average of the other judges should have his points adjusted or his influence in the final rating diminished.
\item The variance of the ratings for a given judge and caracteristic should also be included in the equation
\end{itemize}

\subsection*{Proposed method}
At first we could be tempted to simply adapt the iterative filtering to each characteristic independently. This would of course lead to the basic scheme described in \cite{Cristo1} for each characteristic.\\
In order to be more complete, we need to include the dependence of one characteristic according to another.
The model we propose uses the correlation between two characteristics to address this issue.
Let $C_i$ be the covariance matrix between characteristics for the judge $i$.
We define the "partiality" function as follows :
$$\gamma_{i}(X,r,\Delta,C) = \log (\prod_j \sqrt{\frac{1}{(2\pi)^{K}\det C}} \exp^{- (X_{ij}-r_j-\Delta_i)^TC^{-1} (X_{ij}-r_j-\Delta_i)/2})$$
Where $X_{ij}$ is the column-vector of all the ratings given by the judge $i$ for object $j$, $r_j$ is the column-vector of the reputation of object $j$ in all characteristics and $\Delta_i$ is the column-vector of bias for $i$.\\
The "bias" function is denoted as $\beta(\Delta)$. It is used to penalize too low or high means. It is still to be proposed.\\
We could also influence on the weights for each rating by introducing some tuning parameter $\psi_{jk}$.
Thus the final filtering function would be given by 
$$G_{ijk}(r,X) = \gamma_{i}(X,r,\Delta,C) + \beta_i(\Delta)+\psi_{jk}$$

As we can see, this iteration scheme should satisfy the specifications : 
\begin{itemize}
\item A judge that has an inconsistent rating to an object will have a lower weight. If the covariance between two characteristics is strictly positive, the reputation in two different characteristics tend to increase together.
\item The bias function handles the average of some judges that could be deemed as inappropriate.
\item Different variances lead to different penalizations in the scheme (a higher variance for a judge and characteristic means we are less severe with this judge).
\end{itemize}

\subsection*{Corrected scheme}
$$F_{jk}(w,X) = \frac{\sum_{i}x_{ijk}w_{i}}{\sum_i w_{i}}$$
$$G_{i}(X,r,C) = \log (\prod_j \sqrt{\frac{1}{(2\pi)^{K}\det C}} \exp^{- (X_{ij}-r_j-\Delta_i)^TC^{-1} (X_{ij}-r_j-\Delta_i)/2})$$
which is equivalent to
$$G_{i}(X,r,C) = 1 - \frac{\sum_i (X_{i,j,:}-r{j,:})^TC^{-1}(X_{i,j,:}-r{j,:})}{N/2(-\log(2\pi )^K \det C)}$$
$$G_{i}(X,r,C) = 1 -k superd_i$$
with $k= \frac{2}{(-\log(2\pi )^K \det C)}$ and $superd_i =  \frac{1}{N}\sum_{j} (X_{i,j,:}-r_{j,:})^T C^{-1} (X_{i,j,:}-r_{j,:})$


\subsection*{Energy function for the method}

\begin{tabular}{|c|c|}
\hline 
Tensor & size\\
\hline
$X$ & $N\times M \times K$\\
\hline
$R$ & $M\times K$\\
\hline
$w$ & $N\times 1$\\
\hline
$C$ & $K\times K$\\
\hline
\end{tabular}

We can see that a fixed point $(x,w)$ of the proposed method is a solution of the following equation :
$$ r_{:,k}^{t+1} (\mathbf{1}^Tw^{star}) = X_{:,:,k}w^{\star} \: \forall k$$
and 
$$ w^{\star} = G(r^{\star})$$

Hence we get from this that
$$(r_{:,k}^{\star} \mathbf{1}^T - X_{:,:,k})\cdot G(r^{\star}) = 0 \: \forall k\in \{1,..,K\}$$


$$g(u) = 1 -ku$$

\begin{eqnarray*}
E(r) & = & \sum_{i=1}^n \int_0^{superd_i(r_j)}g(u) du\\
\frac{\partial E}{\partial r_{jk}} & = & \sum_{i}\frac{\partial E}{\partial superd_i} \cdot \frac{\partial superd_i}{\partial r_{jk}}
\end{eqnarray*}

\begin{eqnarray*}
\frac{\partial superd_i}{\partial r_{jk}} & = & \left[-2 C^{-1}(X_{i,j,:}-r_{j,:})\right]_{k} \\
\frac{\partial E}{\partial superd_i} & = & g(superd_i)\\
\frac{\partial E}{\partial r_{jk}} & = & \sum_{i}g(superd_i) \cdot \left[-2 C^{-1}(X_{i,j,:}-r_{j,:})\right]_{k} 
\end{eqnarray*}

\paragraph{Case $C = I$}

When $C$ is the identity matrix, we simply get that the condition $\frac{\partial E}{\partial r^{\star}_{jk}}=0 \: \forall j,k$ is equivalent to the fact that $(r^{\star},G(r^{\star}))$ is a stationary point of the iteration.





\section{Uniqueness of the stationnary point}

We can prove that the stationnary point corresponding to our problem is unique under some assumptions on $k$.
We need $$k\in \mathcal{K} = \{k\in \mathcal{R}_{\geq 0} | 1 - k \frac{1}{n}\begin{pmatrix} superd_1 \\ superd_2 \\ \vdots \\ superd_n \end{pmatrix} >0 \: \forall r \in \mathcal{H} \}$$
where $\mathcal{H}$ is an hypercube.

The function $E(r)$ can also be written as 
$$ E(r) = \sum_{i=1}^N superd_i - k \frac{superd_i^2}{2} + c$$
If we take $c = \frac{2N}{k}$
Indeed, we then have $$ \sum_{i=1}^N superd_i - k \frac{superd_i^2}{2} + \frac{2N}{k} = -\frac{1}{2k} (1 - 2ksuperd_i + superd_i^2)$$
\\

There is a lemma in \cite{Cristo1} that goes as follows
\begin{lemma}
Let the function $E(r) : \mathcal{R}^n \rightarrow \mathcal{R} : E(r) = z $ be a fourth-order polynomial and let $\mathcal{H}$ be some hypercube in $\mathcal{R}^n$. If 
$$\lim_{||r||\rightarrow \infty} E(r) = - \infty $$
and the steepest descent direction on the boundary of $\mathcal{H}$ points strictly inside $\mathcal{H}$, then $E$ has a unique stationary point in $\mathcal{H}$ which is a minimum.
\end{lemma}
From which follows the following theorem
\begin{theorem}
If $k \in \mathcal{K}$, the system has a unique fixed point $r^{\star}$.
\begin{proof}
The proof is similar to the uni-variable case. We note that it is more likely in our multi-variate case to have some unique rating for some characteristic for an object. However, the given rating will determine the final reputation since the change in the weight of the judge won't change the reputation. In other cases where the characteristic of the object is rated by two judges, it will go to the interior and we can see that $E(r)$ has a unique stationary point in $\mathcal{H}$ which is a minimum and that it is the unique fixed point of the system.
\end{proof}
\end{theorem}




%\begin{table}[h]
%\centering
%\begin{tabular}{|c|c|c|}
%\hline 
%Name & Indexing  & Description \\ 
%\hline
%$N$ &  & The number of judges \\ 
%
%$M$ &  & The number of objects \\ 
%$K$ &  & The number of characteristics \\ 
%$x_{ijk}$ & \parbox[t]{3cm}{$\forall i \in \left\lbrace 1,...,N\right\rbrace$,%\newline
%$j \in \left\lbrace 1,...,M\right\rbrace$,\newline
%$k \in \left\lbrace 1,...,K\right\rbrace$ } &  \parbox[t]{5cm}{The rating given by %judge $i$ to characteristic $k$ of object $j$} \\ 
%$R_{jk}$ & 
%\parbox[t]{3cm}{$\forall j \in \left\lbrace 1,...,M\right\rbrace$,\newline
%$k \in \left\lbrace 1,...,K\right\rbrace$ } & \parbox[t]{5cm}{The intrinsic value of %characteristic $k$ of object $j$}\\ 
%$\Delta_{ijk}$ & 
%\parbox[t]{3cm}{$\forall i \in \left\lbrace 1,...,N\right\rbrace$,\newline
%$j \in \left\lbrace 1,...,M\right\rbrace$,\newline
%$k \in \left\lbrace 1,...,K\right\rbrace$ }
%& \parbox[t]{5cm}{Bias of rating for the rating given by judge $i$ to characteristic %$k$ of object $j$} \\
%$\mu_{ijk}$ & 
%\parbox[t]{3cm}{$\forall i \in \left\lbrace 1,...,N\right\rbrace$,\newline
%$j \in \left\lbrace 1,...,M\right\rbrace$,\newline
%$k \in \left\lbrace 1,...,K\right\rbrace$ } 
%& \parbox[t]{5cm}{Mean of rating for the rating given by judge $i$ to characteristic %$k$ of object $j$($\mu_{ijk} = Q_{jk} + \Delta_{ijk}$)}\\
%$\sigma_{i_1k_1i_2k_2}^2$ &
%\parbox[t]{3cm}{$\forall i_1,i_2 \in \left\lbrace 1,...,M\right\rbrace$,\newline
%$k_1,k_2 \in \left\lbrace 1,...,K\right\rbrace$ }
% & \parbox[t]{5cm}{Variance of rating for the judge $i$ for characteristic $k$}\\
%$w_{ijk}$ & & \parbox[t]{5cm}{Weight of the rating $ijk$}\\
%\hline 

%\end{tabular} 
%\caption{Notations}\label{table:notation}
%\end{table}