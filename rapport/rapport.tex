\documentclass[12pt,a4paper,notitlepage]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}

\usepackage{graphicx}

\usepackage{todonotes}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\title{Description of the project : Reputation of objects and reliability of judges}
\author{Malian De Ron \and Quentin Laurent}
\begin{document}

\maketitle
\section{Introduction}
\subsection*{Context}
In order to illustrate the applications of a reputation system, we take the example of several judges rating participants on the quality of a performance. The partiality of a judge can be detected, and the iterative method developed in \cite{Cristo1} seems to eliminate that kind of behavior by giving judges with high standard deviation in their rating a smaller weight in the final score computation.

However this method is restricted to a single vote per judge/object when one aspect of the performance is rated, i.e. for $N$ judges and $M$ objects. Our aim is to be able to handle reputation systems where the judges rate on $K$ aspects of a performance, for instance the technical and artistic aspects ($K=2$). 
Going even further, the judges could rate the characteristics according to their own mood or point of view. For example, when rating a hotel, someone might think of the swimming pool, service, rooms, .. (characteristics) differently if he comes with his family or his partner (point of view).\\
There is of course more than one approach to this problem. 

\subsection*{Project stages}
We intend to follow three distinct steps in order to make our project gradually evolve. At each step we will validate our theoretical results and our algorithms with tests on real or synthetic data.

\subsubsection*{Comparison between filtering methods}
At first, we will simply compare the iterative filtering presented in \cite{Cristo1} 
 with, e.g. the outlier method. The outlier method consists of suppressing the lowest and highest ratings for each object.\\
 This initial problem should allow us to get acquainted with the filtering methods.

\subsubsection*{Multi-variate version of the reputation system : $N$ judges, $M$ objects, $K$ characteristics}
Objects will be rated on several aspects, building a more complex object profile. The vector of characteristics of the object can be sparse or dense.
This part will deal with objects being rated on different characteristics. 
Here we give several guidelines for the choice of our filtering algorithm. It should be able to handle several cases :
\begin{itemize}
\item A judge rating one object much higher or lower than the others in a characteristic should be given less influence. We must penalize incoherence with the other judges.
\item A judge rating with a mean rating above or below the average of the other judges should have his points adjusted or his influence in the final rating diminished.
\item The variance of the ratings for a given judge and characteristic should also be included in the equation
\end{itemize}

\subsubsection*{Adding a dimension : $N$ judges, $M$ objects, $K$ characteristics and $L$ points of view}
The judges will give ratings according to several points of view. The problem is the same, but its size will be increased and the notations will have to be adjusted to include the additional dimension.
\subsection*{Underlying objectives}
There are several intermediary objectives that we will try and fulfill for each of the project stages outlined above.
\begin{itemize}
\item We need to establish mathematically the convergence of our iteration scheme and possibly find ways to improve it.
\item Analyze a range of behaviours for spammers and cheaters who are trying to influence the final rating in a partial way, in order to check the robustness of our method. Tests on several data sets
\item Interpret our method statistically
\end{itemize}


\newpage
\section{Model and notations}
In this part we will build a rating system for $N$ judges evaluating $M$ objects, each having a set of $K$ different characteristics. 
The judges give the objects some set of ratings $x_{ijk}$ with $i,j,k \in {1..N},{1..M},{1..K}$.
At the end of the iterative process, each rating $i$ will be given a weight $w_{ijk}$ and each object $j$ will be given a set of reputations $r_{jk}$, relative to each characteristic of the object.


\subsection{Description of general filtering methods}
As defined in other works, an iterative filtering(IF) system is composed of two basic functions \cite{Cristo1} : 
\begin{itemize}
\item The reputation function : $F(w,X)=r$
\item The filtering function : $G(r,X)=w$
\end{itemize}
The two of them define an iterative filtering system.\\
In quadratic IF systems, the reputation function is naturally given by the weighted average of the votes.
$$F_{jk}(w,X) = \frac{\sum_{i}x_{ijk}w_{ijk}}{\sum_i w_{ijk}}$$

The filtering method used in the aforementioned paper adapted to a multi-variate system is 
$$G_{ik}(w,X) = \log \prod_j f(x_{ij:}|r,C)$$


\subsection{Proposed method}
At first we could be tempted to simply adapt the iterative filtering to each characteristic independently. This would of course lead to the basic scheme described in \cite{Cristo1} for each characteristic.\\
We want to have a unique weight for each judge. 

\begin{table}
\centering
\begin{tabular}{|c|c|}
\hline 
Tensor & size\\
\hline
$X$ & $N\times M \times K$\\
\hline
$R$ & $M\times K$\\
\hline
$w$ & $N\times 1$\\
\hline
$C$ & $K\times K$\\
\hline
\end{tabular}
\caption{Summary of the tensors in use}
\end{table}

In order to be more complete, we need to include the dependence of one characteristic according to another. The model we propose uses the correlation between two characteristics to address this issue.
Let $C$ be the covariance matrix between characteristics. This means that the rating in two characteristics of an object can be linked in some way.

But then again, the reputation of an object in that precise characteristic would be higher if he truly was better in that characteristic. Introducing covariances would mean that we "allow" some judge (in the sense that we don't reduce its weight too much) to be partial and give incoherent marks if it is consistent with the covariances.

\subsection{Preprocessing : change variance and mean}
Since some judges might more demanding in some characteristics than others, we propose to average all the ratings of a given judge in one characteristic and center them to $0$ (although it may change totally the ratings if the judge has given few ratings for that characteristic(it makes sense that a judge giving less ratings in one characteristic should be brought closer to the mean).

All the ratings should then be divided by their respective variance. If there is only rating for one pair judge-characteristic then it should not be changed.

\subsection{Iteration}
The iteration that we are proposing uses a weight for each judge. Hence the reputation is simply the sum of the characteristics ratings weighted by the weights of all the judges.
$$F_{jk}(w,X) = \frac{\sum_{i}x_{ijk}w_{i}}{\sum_i w_{i}}$$

The filtering method gives lower marks to judges which are more or less far from the current reputation of the object.
$$G_{i}(X,r,C) = \log (\prod_j \sqrt{\frac{1}{(2\pi)^{K}\det C}} \exp^{- (X_{ij}-r_j)^TC^{-1} (X_{ij}-r_j)/2})$$
which is equivalent (when scaled) to
$$G_{i}(X,r,C) = 1 - \frac{\sum_i (X_{i,j,:}-r_{j,:})^TC^{-1}(X_{i,j,:}-r_{j,:})}{N(-\log(2\pi )^K \det C)}$$
$$G_{i}(X,r,C) = 1 -k superd_i$$
with $k= \frac{1}{(-\log(2\pi )^K \det C)}$ and $superd_i =  \frac{1}{N}\sum_{j} (X_{i,j,:}-r_{j,:})^T C^{-1} (X_{i,j,:}-r_{j,:})$\\


As we can see, this iteration scheme should satisfy the specifications : 
\begin{itemize}
\item A judge that has an inconsistent rating to an object will have a lower weight. If the covariance between two characteristics is strictly positive, the reputation in two different characteristics tend to increase together.
\item The bias function handles the average of some judges that could be deemed as inappropriate.
\item Different variances lead to different penalizations in the scheme (a higher variance for a judge and characteristic means we are less severe with this judge).
\end{itemize}

\section{Properties of the method}
\subsection{Energy function for the method}
We can see that a fixed point $(x,w)$ of the proposed method is a solution of the following equation :
$$ r_{:,k}^{t+1} (\mathbf{1}^Tw^{star}) = X_{:,:,k}w^{\star} \:\: \forall k$$
Which is simply a rewriting of the reputation function and \todo{Tensor notation !!!}
$$ w^{\star} = G(r^{\star})$$

Hence we get by replacing appropriately that
\begin{align*}
(r_{:,k}^{\star} \mathbf{1}^T - X_{:,:,k})\cdot G(r^{\star}) &= 0 & \forall k\in \{1,..,K\}
\end{align*}

We define an energy function that we intend to minimize
\begin{eqnarray*}
E(r) & = & \sum_{i=1}^n \int_0^{superd_i(r)}g(u) du\\
\end{eqnarray*}
with $g(u) = 1 -ku$

The stationary points have zero gradient for each component.
$$
\frac{\partial E}{\partial r_{jk}} =  \sum_{i}\frac{\partial E}{\partial superd_i} \cdot \frac{\partial superd_i}{\partial r_{jk}} = 0
$$
The above formula is derived from the chain rule. 
\begin{eqnarray*}
\frac{\partial superd_i}{\partial r_{jk}} & = & \left[-2 C^{-1}(X_{i,j,:}-r_{j,:})\right]_{k} \\
\frac{\partial E}{\partial superd_i} & = & g(superd_i)\\
\frac{\partial E}{\partial r_{jk}} & = & \sum_{i}g(superd_i) \cdot \left[-2 C^{-1}(X_{i,j,:}-r_{j,:})\right]_{k} 
\end{eqnarray*}

\subsubsection*{Case $C = I$}
We notice that if the covariance matrix is the identity, the fixed points of the iteration correspond to the stationary points of the energy function, given by :

When $C$ is the identity matrix, we simply get that the condition $\frac{\partial E}{\partial r^{\star}_{jk}}=0 \: \forall j,k$ is equivalent to the fact that $(r^{\star},G(r^{\star}))$ is a stationary point of the iteration.


\subsection{Uniqueness of the stationnary point}

We can prove that the stationnary point corresponding to our problem is unique under some assumptions on $k$.
We need $$k\in \mathcal{K} = \{k\in \mathcal{R}_{\geq 0} | 1 - k \begin{pmatrix} superd_1 \\ superd_2 \\ \vdots \\ superd_n \end{pmatrix} >0 \: \forall r \in \mathcal{H} \}$$
where $\mathcal{H}$ is an hypercube. We can also develop the expression of the energy function $E(r)$ and rewrite it as
$$ E(r) = \sum_{i=1}^N superd_i - k \frac{superd_i^2}{2} + c$$
If we take $c = \frac{2N}{k}$
Indeed, we then have $$ \sum_{i=1}^N superd_i - k \frac{superd_i^2}{2} + \frac{2N}{k} = -\frac{1}{2k} w^Tw = -\frac{1}{2k}(1 - 2ksuperd_i + superd_i^2)$$
\\

There is a lemma in \cite{Cristo1} that goes as follows
\begin{lemma}
Let the function $E(r) : \mathcal{R}^n \rightarrow \mathcal{R} : E(r) = z $ be a fourth-order polynomial and let $\mathcal{H}$ be some hypercube in $\mathcal{R}^n$. If 
$$\lim_{||r||\rightarrow \infty} E(r) = - \infty $$
and the steepest descent direction on the boundary of $\mathcal{H}$ points strictly inside $\mathcal{H}$, then $E$ has a unique stationary point in $\mathcal{H}$ which is a minimum.
\end{lemma}
From which follows the following theorem
\begin{theorem}
If $k \in \mathcal{K}$, the system has a unique fixed point $r^{\star}$.
\begin{proof}
The proof is similar to the uni-variable case. We note that it is more likely in our multi-variate case to have some unique rating for some characteristic for an object. However, the given rating will determine the final reputation since the change in the weight of the judge won't change the reputation. In other cases where the characteristic of the object is rated by two judges, it will go to the interior and we can see that $E(r)$ has a unique stationary point in $\mathcal{H}$ which is a minimum and that it is the unique fixed point of the system.
\end{proof}
\end{theorem}


\bibliographystyle{plain}
\bibliography{bib/biblio}
\nocite{*}


\end{document}